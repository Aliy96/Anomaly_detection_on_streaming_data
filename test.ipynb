{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Window params: {'L_S': 100, 'N_PRED': 1, 'STRIDE': 1}\n",
      "Train params: {'BATCH_SIZE': 256, 'EPOCHS': 50, 'LR': 0.0001, 'VAL_FRAC': 0.2}\n",
      "Loaded labels: (82, 5)\n",
      "  chan_id spacecraft                           anomaly_sequences  \\\n",
      "0     P-1       SMAP  [[2149, 2349], [4536, 4844], [3539, 3779]]   \n",
      "1     S-1       SMAP                              [[5300, 5747]]   \n",
      "2     E-1       SMAP                [[5000, 5030], [5610, 6086]]   \n",
      "\n",
      "                                  class  num_values  \n",
      "0  [contextual, contextual, contextual]        8505  \n",
      "1                               [point]        7331  \n",
      "2              [contextual, contextual]        8516  \n",
      "\n",
      "Total channels to run: 82\n",
      "\n",
      "\n",
      "[P-1] train_windows=2217 val_windows=554 test_windows=8404 F_in=24\n",
      "  epoch   1/50  train_mse=0.451543  val_mse=0.193827\n",
      "  epoch  10/50  train_mse=0.157447  val_mse=0.191873\n",
      "  epoch  20/50  train_mse=0.154448  val_mse=0.190271\n",
      "  epoch  30/50  train_mse=0.149726  val_mse=0.186310\n",
      "  epoch  40/50  train_mse=0.145591  val_mse=0.185100\n",
      "  epoch  50/50  train_mse=0.146130  val_mse=0.185137\n",
      "[P-1] thr=0.183677  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[S-1] train_windows=2174 val_windows=543 test_windows=7230 F_in=24\n",
      "  epoch   1/50  train_mse=0.280594  val_mse=0.225047\n",
      "  epoch  10/50  train_mse=0.203754  val_mse=0.223784\n",
      "  epoch  20/50  train_mse=0.202103  val_mse=0.207614\n",
      "  epoch  30/50  train_mse=0.201962  val_mse=0.207456\n",
      "  epoch  40/50  train_mse=0.201625  val_mse=0.207821\n",
      "  epoch  50/50  train_mse=0.201530  val_mse=0.207989\n",
      "[S-1] thr=0.163716  P=0.768 R=1.000 F1=0.869\n",
      "\n",
      "[E-1] train_windows=2224 val_windows=555 test_windows=8415 F_in=24\n",
      "  epoch   1/50  train_mse=0.679016  val_mse=0.582366\n",
      "  epoch  10/50  train_mse=0.670072  val_mse=0.583136\n",
      "  epoch  20/50  train_mse=0.570798  val_mse=0.469847\n",
      "  epoch  30/50  train_mse=0.506752  val_mse=0.467769\n",
      "  epoch  40/50  train_mse=0.476427  val_mse=0.475387\n",
      "  epoch  50/50  train_mse=0.476281  val_mse=0.463519\n",
      "[E-1] thr=0.274454  P=0.903 R=0.941 F1=0.922\n",
      "\n",
      "[E-2] train_windows=2224 val_windows=555 test_windows=8431 F_in=24\n",
      "  epoch   1/50  train_mse=0.338565  val_mse=0.272347\n",
      "  epoch  10/50  train_mse=0.268860  val_mse=0.264082\n",
      "  epoch  20/50  train_mse=0.262482  val_mse=0.261854\n",
      "  epoch  30/50  train_mse=0.253904  val_mse=0.260939\n",
      "  epoch  40/50  train_mse=0.251940  val_mse=0.260550\n",
      "  epoch  50/50  train_mse=0.249893  val_mse=0.260471\n",
      "[E-2] thr=0.193617  P=0.929 R=1.000 F1=0.963\n",
      "\n",
      "[E-3] train_windows=2224 val_windows=555 test_windows=8206 F_in=24\n",
      "  epoch   1/50  train_mse=0.228347  val_mse=0.324969\n",
      "  epoch  10/50  train_mse=0.078531  val_mse=0.201668\n",
      "  epoch  20/50  train_mse=0.078093  val_mse=0.180955\n",
      "  epoch  30/50  train_mse=0.075245  val_mse=0.158606\n",
      "  epoch  40/50  train_mse=0.072614  val_mse=0.135693\n",
      "  epoch  50/50  train_mse=0.072238  val_mse=0.138401\n",
      "[E-3] thr=0.140888  P=0.881 R=1.000 F1=0.937\n",
      "\n",
      "[E-4] train_windows=2224 val_windows=555 test_windows=8253 F_in=24\n",
      "  epoch   1/50  train_mse=0.490382  val_mse=0.258688\n",
      "  epoch  10/50  train_mse=0.149566  val_mse=0.144109\n",
      "  epoch  20/50  train_mse=0.144316  val_mse=0.142093\n",
      "  epoch  30/50  train_mse=0.138715  val_mse=0.129195\n",
      "  epoch  40/50  train_mse=0.130206  val_mse=0.120999\n",
      "  epoch  50/50  train_mse=0.127498  val_mse=0.117982\n",
      "[E-4] thr=0.161625  P=0.984 R=1.000 F1=0.992\n",
      "\n",
      "[E-5] train_windows=2224 val_windows=555 test_windows=8193 F_in=24\n",
      "  epoch   1/50  train_mse=1.333794  val_mse=0.613720\n",
      "  epoch  10/50  train_mse=0.674183  val_mse=0.575777\n",
      "  epoch  20/50  train_mse=0.594515  val_mse=0.529919\n",
      "  epoch  30/50  train_mse=0.538325  val_mse=0.523621\n",
      "  epoch  40/50  train_mse=0.492931  val_mse=0.498459\n",
      "  epoch  50/50  train_mse=0.491314  val_mse=0.505925\n",
      "[E-5] thr=0.276373  P=1.000 R=1.000 F1=1.000\n",
      "\n",
      "[E-6] train_windows=2224 val_windows=555 test_windows=8199 F_in=24\n",
      "  epoch   1/50  train_mse=0.095070  val_mse=0.003478\n",
      "  epoch  10/50  train_mse=0.000198  val_mse=0.000747\n",
      "  epoch  20/50  train_mse=0.000157  val_mse=0.000404\n",
      "  epoch  30/50  train_mse=0.000142  val_mse=0.000446\n",
      "  epoch  40/50  train_mse=0.000130  val_mse=0.000407\n",
      "  epoch  50/50  train_mse=0.000136  val_mse=0.000425\n",
      "[E-6] thr=0.003270  P=0.110 R=1.000 F1=0.198\n",
      "\n",
      "[E-7] train_windows=2135 val_windows=533 test_windows=8209 F_in=24\n",
      "  epoch   1/50  train_mse=0.348348  val_mse=0.045274\n",
      "  epoch  10/50  train_mse=0.002175  val_mse=0.002086\n",
      "  epoch  20/50  train_mse=0.002132  val_mse=0.001892\n",
      "  epoch  30/50  train_mse=0.002023  val_mse=0.001966\n",
      "  epoch  40/50  train_mse=0.002069  val_mse=0.002056\n",
      "  epoch  50/50  train_mse=0.002033  val_mse=0.002143\n",
      "[E-7] thr=0.013690  P=0.793 R=1.000 F1=0.885\n",
      "\n",
      "[E-8] train_windows=2224 val_windows=555 test_windows=8431 F_in=24\n",
      "  epoch   1/50  train_mse=0.338704  val_mse=0.494612\n",
      "  epoch  10/50  train_mse=0.172746  val_mse=0.194800\n",
      "  epoch  20/50  train_mse=0.167473  val_mse=0.206716\n",
      "  epoch  30/50  train_mse=0.165649  val_mse=0.208340\n",
      "  epoch  40/50  train_mse=0.164701  val_mse=0.210271\n",
      "  epoch  50/50  train_mse=0.164023  val_mse=0.210787\n",
      "[E-8] thr=0.158087  P=0.938 R=1.000 F1=0.968\n",
      "\n",
      "[E-9] train_windows=2224 val_windows=555 test_windows=8201 F_in=24\n",
      "  epoch   1/50  train_mse=0.257349  val_mse=0.254699\n",
      "  epoch  10/50  train_mse=0.145886  val_mse=0.196239\n",
      "  epoch  20/50  train_mse=0.144188  val_mse=0.181764\n",
      "  epoch  30/50  train_mse=0.145692  val_mse=0.187817\n",
      "  epoch  40/50  train_mse=0.142970  val_mse=0.186646\n",
      "  epoch  50/50  train_mse=0.143214  val_mse=0.182767\n",
      "[E-9] thr=0.124883  P=0.454 R=1.000 F1=0.624\n",
      "\n",
      "[E-10] train_windows=2224 val_windows=555 test_windows=8404 F_in=24\n",
      "  epoch   1/50  train_mse=1.011223  val_mse=0.590548\n",
      "  epoch  10/50  train_mse=0.670809  val_mse=0.579390\n",
      "  epoch  20/50  train_mse=0.621667  val_mse=0.528723\n",
      "  epoch  30/50  train_mse=0.538117  val_mse=0.550313\n",
      "  epoch  40/50  train_mse=0.509869  val_mse=0.625189\n",
      "  epoch  50/50  train_mse=0.487711  val_mse=0.604536\n",
      "[E-10] thr=0.253969  P=0.358 R=1.000 F1=0.528\n",
      "\n",
      "[E-11] train_windows=2224 val_windows=555 test_windows=8413 F_in=24\n",
      "  epoch   1/50  train_mse=1.212205  val_mse=0.696523\n",
      "  epoch  10/50  train_mse=0.672788  val_mse=0.587771\n",
      "  epoch  20/50  train_mse=0.642723  val_mse=0.544587\n",
      "  epoch  30/50  train_mse=0.545711  val_mse=0.516352\n",
      "  epoch  40/50  train_mse=0.494394  val_mse=0.483314\n",
      "  epoch  50/50  train_mse=0.490582  val_mse=0.478250\n",
      "[E-11] thr=0.263790  P=0.296 R=0.829 F1=0.437\n",
      "\n",
      "[E-12] train_windows=2224 val_windows=555 test_windows=8411 F_in=24\n",
      "  epoch   1/50  train_mse=0.974909  val_mse=0.680104\n",
      "  epoch  10/50  train_mse=0.675550  val_mse=0.588638\n",
      "  epoch  20/50  train_mse=0.656421  val_mse=0.595617\n",
      "  epoch  30/50  train_mse=0.556094  val_mse=0.497918\n",
      "  epoch  40/50  train_mse=0.528079  val_mse=0.445702\n",
      "  epoch  50/50  train_mse=0.514521  val_mse=0.429772\n",
      "[E-12] thr=0.247428  P=0.487 R=1.000 F1=0.655\n",
      "\n",
      "[E-13] train_windows=2224 val_windows=555 test_windows=8539 F_in=24\n",
      "  epoch   1/50  train_mse=0.534692  val_mse=0.335833\n",
      "  epoch  10/50  train_mse=0.289468  val_mse=0.297926\n",
      "  epoch  20/50  train_mse=0.288324  val_mse=0.297085\n",
      "  epoch  30/50  train_mse=0.257054  val_mse=0.298688\n",
      "  epoch  40/50  train_mse=0.249727  val_mse=0.315248\n",
      "  epoch  50/50  train_mse=0.247031  val_mse=0.316446\n",
      "[E-13] thr=0.229979  P=0.918 R=0.387 F1=0.544\n",
      "\n",
      "[A-1] train_windows=2224 val_windows=555 test_windows=8539 F_in=24\n",
      "  epoch   1/50  train_mse=0.118420  val_mse=0.000918\n",
      "  epoch  10/50  train_mse=0.000209  val_mse=0.000945\n",
      "  epoch  20/50  train_mse=0.000155  val_mse=0.000727\n",
      "  epoch  30/50  train_mse=0.000134  val_mse=0.000444\n",
      "  epoch  40/50  train_mse=0.000129  val_mse=0.000458\n",
      "  epoch  50/50  train_mse=0.000128  val_mse=0.000513\n",
      "[A-1] thr=0.002591  P=0.125 R=1.000 F1=0.222\n",
      "\n",
      "[D-1] train_windows=2199 val_windows=549 test_windows=8408 F_in=24\n",
      "  epoch   1/50  train_mse=0.609388  val_mse=0.075049\n",
      "  epoch  10/50  train_mse=0.003342  val_mse=0.004669\n",
      "  epoch  20/50  train_mse=0.003390  val_mse=0.004926\n",
      "  epoch  30/50  train_mse=0.003235  val_mse=0.004364\n",
      "  epoch  40/50  train_mse=0.003229  val_mse=0.004527\n",
      "  epoch  50/50  train_mse=0.003237  val_mse=0.004596\n",
      "[D-1] thr=0.025042  P=0.976 R=1.000 F1=0.988\n",
      "\n",
      "[P-2] train_windows=2176 val_windows=544 test_windows=8108 F_in=24\n",
      "  epoch   1/50  train_mse=0.115373  val_mse=0.087395\n",
      "  epoch  10/50  train_mse=0.001007  val_mse=0.001279\n",
      "  epoch  20/50  train_mse=0.000993  val_mse=0.000822\n",
      "  epoch  30/50  train_mse=0.000975  val_mse=0.001299\n",
      "  epoch  40/50  train_mse=0.000962  val_mse=0.000984\n",
      "  epoch  50/50  train_mse=0.000947  val_mse=0.001070\n",
      "[P-2] thr=0.010085  P=0.466 R=1.000 F1=0.635\n",
      "\n",
      "[P-3] train_windows=2204 val_windows=550 test_windows=8392 F_in=24\n",
      "  epoch   1/50  train_mse=0.130954  val_mse=0.096148\n",
      "  epoch  10/50  train_mse=0.087887  val_mse=0.081922\n",
      "  epoch  20/50  train_mse=0.085675  val_mse=0.090975\n",
      "  epoch  30/50  train_mse=0.082877  val_mse=0.083469\n",
      "  epoch  40/50  train_mse=0.080918  val_mse=0.088841\n",
      "  epoch  50/50  train_mse=0.080116  val_mse=0.089920\n",
      "[P-3] thr=0.104186  P=1.000 R=1.000 F1=1.000\n",
      "\n",
      "[D-2] train_windows=2224 val_windows=555 test_windows=8494 F_in=24\n",
      "  epoch   1/50  train_mse=0.085930  val_mse=0.006362\n",
      "  epoch  10/50  train_mse=0.000142  val_mse=0.000436\n",
      "  epoch  20/50  train_mse=0.000115  val_mse=0.000413\n",
      "  epoch  30/50  train_mse=0.000104  val_mse=0.000512\n",
      "  epoch  40/50  train_mse=0.000099  val_mse=0.000449\n",
      "  epoch  50/50  train_mse=0.000090  val_mse=0.000435\n",
      "[D-2] thr=0.001822  P=0.922 R=1.000 F1=0.959\n",
      "\n",
      "[D-3] train_windows=2224 val_windows=555 test_windows=8539 F_in=24\n",
      "  epoch   1/50  train_mse=0.019191  val_mse=0.003492\n",
      "  epoch  10/50  train_mse=0.000235  val_mse=0.001487\n",
      "  epoch  20/50  train_mse=0.000198  val_mse=0.001703\n",
      "  epoch  30/50  train_mse=0.000181  val_mse=0.001217\n",
      "  epoch  40/50  train_mse=0.000152  val_mse=0.001435\n",
      "  epoch  50/50  train_mse=0.000161  val_mse=0.001391\n",
      "[D-3] thr=0.004219  P=0.910 R=1.000 F1=0.953\n",
      "\n",
      "[D-4] train_windows=2186 val_windows=546 test_windows=8372 F_in=24\n",
      "  epoch   1/50  train_mse=0.310606  val_mse=0.023729\n",
      "  epoch  10/50  train_mse=0.000248  val_mse=0.001407\n",
      "  epoch  20/50  train_mse=0.000210  val_mse=0.001536\n",
      "  epoch  30/50  train_mse=0.000178  val_mse=0.001442\n",
      "  epoch  40/50  train_mse=0.000183  val_mse=0.001494\n",
      "  epoch  50/50  train_mse=0.000170  val_mse=0.001326\n",
      "[D-4] thr=0.003553  P=0.578 R=1.000 F1=0.732\n",
      "\n",
      "[A-2] train_windows=2038 val_windows=509 test_windows=7813 F_in=24\n",
      "  epoch   1/50  train_mse=0.439364  val_mse=0.356556\n",
      "  epoch  10/50  train_mse=0.315959  val_mse=0.337567\n",
      "  epoch  20/50  train_mse=0.312746  val_mse=0.347769\n",
      "  epoch  30/50  train_mse=0.312615  val_mse=0.336915\n",
      "  epoch  40/50  train_mse=0.309859  val_mse=0.336507\n",
      "  epoch  50/50  train_mse=0.309277  val_mse=0.336413\n",
      "[A-2] thr=0.141478  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[A-3] train_windows=2108 val_windows=527 test_windows=8104 F_in=24\n",
      "  epoch   1/50  train_mse=0.267164  val_mse=0.215701\n",
      "  epoch  10/50  train_mse=0.220718  val_mse=0.257219\n",
      "  epoch  20/50  train_mse=0.217581  val_mse=0.265632\n",
      "  epoch  30/50  train_mse=0.216707  val_mse=0.248566\n",
      "  epoch  40/50  train_mse=0.214575  val_mse=0.241281\n",
      "  epoch  50/50  train_mse=0.213928  val_mse=0.245958\n",
      "[A-3] thr=0.123802  P=0.481 R=1.000 F1=0.649\n",
      "\n",
      "[A-4] train_windows=2072 val_windows=517 test_windows=7979 F_in=24\n",
      "  epoch   1/50  train_mse=0.143505  val_mse=0.119829\n",
      "  epoch  10/50  train_mse=0.126219  val_mse=0.165326\n",
      "  epoch  20/50  train_mse=0.124627  val_mse=0.122449\n",
      "  epoch  30/50  train_mse=0.123855  val_mse=0.132651\n",
      "  epoch  40/50  train_mse=0.122851  val_mse=0.125377\n",
      "  epoch  50/50  train_mse=0.122580  val_mse=0.126703\n",
      "[A-4] thr=0.092196  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[G-1] train_windows=2176 val_windows=543 test_windows=8368 F_in=24\n",
      "  epoch   1/50  train_mse=0.237353  val_mse=0.466438\n",
      "  epoch  10/50  train_mse=0.214564  val_mse=0.313929\n",
      "  epoch  20/50  train_mse=0.207620  val_mse=0.321219\n",
      "  epoch  30/50  train_mse=0.194598  val_mse=0.499211\n",
      "  epoch  40/50  train_mse=0.186656  val_mse=0.452621\n",
      "  epoch  50/50  train_mse=0.185590  val_mse=0.443568\n",
      "[G-1] thr=0.141121  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[G-2] train_windows=1902 val_windows=475 test_windows=7260 F_in=24\n",
      "  epoch   1/50  train_mse=0.035546  val_mse=0.015368\n",
      "  epoch  10/50  train_mse=0.000242  val_mse=0.000768\n",
      "  epoch  20/50  train_mse=0.000160  val_mse=0.000579\n",
      "  epoch  30/50  train_mse=0.000152  val_mse=0.000533\n",
      "  epoch  40/50  train_mse=0.000147  val_mse=0.000505\n",
      "  epoch  50/50  train_mse=0.000147  val_mse=0.000496\n",
      "[G-2] thr=0.002615  P=0.129 R=1.000 F1=0.229\n",
      "\n",
      "[D-5] train_windows=1968 val_windows=492 test_windows=7527 F_in=24\n",
      "  epoch   1/50  train_mse=0.264475  val_mse=0.010074\n",
      "  epoch  10/50  train_mse=0.000154  val_mse=0.000481\n",
      "  epoch  20/50  train_mse=0.000138  val_mse=0.000541\n",
      "  epoch  30/50  train_mse=0.000126  val_mse=0.000516\n",
      "  epoch  40/50  train_mse=0.000117  val_mse=0.000544\n",
      "  epoch  50/50  train_mse=0.000120  val_mse=0.000497\n",
      "[D-5] thr=0.003215  P=0.007 R=1.000 F1=0.013\n",
      "\n",
      "[D-6] train_windows=1995 val_windows=498 test_windows=7783 F_in=24\n",
      "  epoch   1/50  train_mse=0.241326  val_mse=0.102554\n",
      "  epoch  10/50  train_mse=0.093753  val_mse=0.163962\n",
      "  epoch  20/50  train_mse=0.071149  val_mse=0.133802\n",
      "  epoch  30/50  train_mse=0.065741  val_mse=0.124639\n",
      "  epoch  40/50  train_mse=0.059779  val_mse=0.135309\n",
      "  epoch  50/50  train_mse=0.058436  val_mse=0.136292\n",
      "[D-6] thr=0.097188  P=0.016 R=1.000 F1=0.031\n",
      "\n",
      "[D-7] train_windows=1986 val_windows=496 test_windows=7541 F_in=24\n",
      "  epoch   1/50  train_mse=0.030160  val_mse=0.011349\n",
      "  epoch  10/50  train_mse=0.000189  val_mse=0.000587\n",
      "  epoch  20/50  train_mse=0.000145  val_mse=0.000565\n",
      "  epoch  30/50  train_mse=0.000147  val_mse=0.000359\n",
      "  epoch  40/50  train_mse=0.000140  val_mse=0.000412\n",
      "  epoch  50/50  train_mse=0.000125  val_mse=0.000389\n",
      "[D-7] thr=0.002492  P=0.800 R=1.000 F1=0.889\n",
      "\n",
      "[F-1] train_windows=2215 val_windows=553 test_windows=8483 F_in=24\n",
      "  epoch   1/50  train_mse=0.073365  val_mse=0.046057\n",
      "  epoch  10/50  train_mse=0.052014  val_mse=0.045289\n",
      "  epoch  20/50  train_mse=0.049776  val_mse=0.045135\n",
      "  epoch  30/50  train_mse=0.048102  val_mse=0.045863\n",
      "  epoch  40/50  train_mse=0.048008  val_mse=0.045218\n",
      "  epoch  50/50  train_mse=0.047934  val_mse=0.045220\n",
      "[F-1] thr=0.116261  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[P-4] train_windows=2007 val_windows=501 test_windows=7682 F_in=24\n",
      "  epoch   1/50  train_mse=0.110265  val_mse=0.032291\n",
      "  epoch  10/50  train_mse=0.000199  val_mse=0.000557\n",
      "  epoch  20/50  train_mse=0.000159  val_mse=0.000692\n",
      "  epoch  30/50  train_mse=0.000144  val_mse=0.000754\n",
      "  epoch  40/50  train_mse=0.000138  val_mse=0.000634\n",
      "  epoch  50/50  train_mse=0.000139  val_mse=0.000657\n",
      "[P-4] thr=0.001852  P=0.973 R=1.000 F1=0.987\n",
      "\n",
      "[G-3] train_windows=2019 val_windows=504 test_windows=7806 F_in=24\n",
      "  epoch   1/50  train_mse=0.326087  val_mse=0.054134\n",
      "  epoch  10/50  train_mse=0.030242  val_mse=0.000042\n",
      "  epoch  20/50  train_mse=0.029071  val_mse=0.000556\n",
      "  epoch  30/50  train_mse=0.028081  val_mse=0.001075\n",
      "  epoch  40/50  train_mse=0.027235  val_mse=0.001309\n",
      "  epoch  50/50  train_mse=0.026857  val_mse=0.001079\n",
      "[G-3] thr=0.002750  P=0.029 R=1.000 F1=0.056\n",
      "\n",
      "[T-1] train_windows=2220 val_windows=554 test_windows=8511 F_in=24\n",
      "  epoch   1/50  train_mse=0.520179  val_mse=0.536834\n",
      "  epoch  10/50  train_mse=0.366733  val_mse=0.402621\n",
      "  epoch  20/50  train_mse=0.364619  val_mse=0.399826\n",
      "  epoch  30/50  train_mse=0.364433  val_mse=0.390399\n",
      "  epoch  40/50  train_mse=0.365069  val_mse=0.390364\n",
      "  epoch  50/50  train_mse=0.364142  val_mse=0.392509\n",
      "[T-1] thr=0.215896  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[T-2] train_windows=2204 val_windows=550 test_windows=8524 F_in=24\n",
      "  epoch   1/50  train_mse=0.399625  val_mse=0.390796\n",
      "  epoch  10/50  train_mse=0.369908  val_mse=0.391383\n",
      "  epoch  20/50  train_mse=0.371236  val_mse=0.390849\n",
      "  epoch  30/50  train_mse=0.368561  val_mse=0.394990\n",
      "  epoch  40/50  train_mse=0.366033  val_mse=0.394463\n",
      "  epoch  50/50  train_mse=0.364906  val_mse=0.392865\n",
      "[T-2] thr=0.216182  P=0.996 R=1.000 F1=0.998\n",
      "\n",
      "[D-8] train_windows=2001 val_windows=500 test_windows=7773 F_in=24\n",
      "  epoch   1/50  train_mse=0.020751  val_mse=0.000003\n",
      "  epoch  10/50  train_mse=0.000190  val_mse=0.000737\n",
      "  epoch  20/50  train_mse=0.000152  val_mse=0.001033\n",
      "  epoch  30/50  train_mse=0.000145  val_mse=0.000756\n",
      "  epoch  40/50  train_mse=0.000128  val_mse=0.000608\n",
      "  epoch  50/50  train_mse=0.000130  val_mse=0.000629\n",
      "[D-8] thr=0.000268  P=0.122 R=1.000 F1=0.218\n",
      "\n",
      "[D-9] train_windows=1986 val_windows=496 test_windows=7305 F_in=24\n",
      "  epoch   1/50  train_mse=0.330599  val_mse=0.080451\n",
      "  epoch  10/50  train_mse=0.000188  val_mse=0.000394\n",
      "  epoch  20/50  train_mse=0.000100  val_mse=0.000348\n",
      "  epoch  30/50  train_mse=0.000093  val_mse=0.000441\n",
      "  epoch  40/50  train_mse=0.000090  val_mse=0.000464\n",
      "  epoch  50/50  train_mse=0.000094  val_mse=0.000438\n",
      "[D-9] thr=0.000150  P=0.762 R=1.000 F1=0.865\n",
      "\n",
      "[F-2] train_windows=2208 val_windows=552 test_windows=8525 F_in=24\n",
      "  epoch   1/50  train_mse=0.061153  val_mse=0.027526\n",
      "  epoch  10/50  train_mse=0.031343  val_mse=0.027749\n",
      "  epoch  20/50  train_mse=0.030549  val_mse=0.027835\n",
      "  epoch  30/50  train_mse=0.030577  val_mse=0.027523\n",
      "  epoch  40/50  train_mse=0.029943  val_mse=0.027520\n",
      "  epoch  50/50  train_mse=0.029981  val_mse=0.027528\n",
      "[F-2] thr=0.122054  P=1.000 R=1.000 F1=1.000\n",
      "\n",
      "[G-4] train_windows=1960 val_windows=490 test_windows=7531 F_in=24\n",
      "  epoch   1/50  train_mse=0.045308  val_mse=0.024888\n",
      "  epoch  10/50  train_mse=0.000256  val_mse=0.001192\n",
      "  epoch  20/50  train_mse=0.000226  val_mse=0.000624\n",
      "  epoch  30/50  train_mse=0.000210  val_mse=0.000616\n",
      "  epoch  40/50  train_mse=0.000195  val_mse=0.000581\n",
      "  epoch  50/50  train_mse=0.000186  val_mse=0.000589\n",
      "[G-4] thr=0.002179  P=1.000 R=1.000 F1=1.000\n",
      "\n",
      "[T-3] train_windows=2220 val_windows=555 test_windows=8478 F_in=24\n",
      "  epoch   1/50  train_mse=0.118207  val_mse=0.113191\n",
      "  epoch  10/50  train_mse=0.000457  val_mse=0.000449\n",
      "  epoch  20/50  train_mse=0.000374  val_mse=0.000375\n",
      "  epoch  30/50  train_mse=0.000363  val_mse=0.000399\n",
      "  epoch  40/50  train_mse=0.000363  val_mse=0.000657\n",
      "  epoch  50/50  train_mse=0.000377  val_mse=0.000567\n",
      "[T-3] thr=0.004527  P=1.000 R=1.000 F1=1.000\n",
      "\n",
      "[D-11] train_windows=2008 val_windows=502 test_windows=7330 F_in=24\n",
      "  epoch   1/50  train_mse=0.197699  val_mse=1.077083\n",
      "  epoch  10/50  train_mse=0.065689  val_mse=1.092688\n",
      "  epoch  20/50  train_mse=0.063220  val_mse=1.037224\n",
      "  epoch  30/50  train_mse=0.061267  val_mse=0.977386\n",
      "  epoch  40/50  train_mse=0.060908  val_mse=1.008704\n",
      "  epoch  50/50  train_mse=0.061007  val_mse=0.990596\n",
      "[D-11] thr=0.177240  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[D-12] train_windows=169 val_windows=42 test_windows=7817 F_in=24\n",
      "  epoch   1/50  train_mse=1.962685  val_mse=0.831989\n",
      "  epoch  10/50  train_mse=0.052701  val_mse=0.046779\n",
      "  epoch  20/50  train_mse=0.006601  val_mse=0.002147\n",
      "  epoch  30/50  train_mse=0.001026  val_mse=0.000428\n",
      "  epoch  40/50  train_mse=0.000411  val_mse=0.000118\n",
      "  epoch  50/50  train_mse=0.000202  val_mse=0.000862\n",
      "[D-12] thr=0.000716  P=0.857 R=1.000 F1=0.923\n",
      "\n",
      "[B-1] train_windows=1868 val_windows=466 test_windows=7943 F_in=24\n",
      "  epoch   1/50  train_mse=0.318220  val_mse=0.048697\n",
      "  epoch  10/50  train_mse=0.000161  val_mse=0.000961\n",
      "  epoch  20/50  train_mse=0.000138  val_mse=0.000548\n",
      "  epoch  30/50  train_mse=0.000117  val_mse=0.000425\n",
      "  epoch  40/50  train_mse=0.000115  val_mse=0.000584\n",
      "  epoch  50/50  train_mse=0.000113  val_mse=0.000569\n",
      "[B-1] thr=0.000722  P=0.021 R=1.000 F1=0.040\n",
      "\n",
      "[G-6] train_windows=2224 val_windows=556 test_windows=8539 F_in=24\n",
      "  epoch   1/50  train_mse=0.474947  val_mse=0.649784\n",
      "  epoch  10/50  train_mse=0.114647  val_mse=0.689660\n",
      "  epoch  20/50  train_mse=0.110824  val_mse=0.713936\n",
      "  epoch  30/50  train_mse=0.105632  val_mse=0.657305\n",
      "  epoch  40/50  train_mse=0.104537  val_mse=0.660684\n",
      "  epoch  50/50  train_mse=0.104618  val_mse=0.676392\n",
      "[G-6] thr=0.133799  P=0.061 R=1.000 F1=0.114\n",
      "\n",
      "[G-7] train_windows=1876 val_windows=469 test_windows=7928 F_in=24\n",
      "  epoch   1/50  train_mse=0.299345  val_mse=0.060089\n",
      "  epoch  10/50  train_mse=0.030377  val_mse=0.043261\n",
      "  epoch  20/50  train_mse=0.030748  val_mse=0.042270\n",
      "  epoch  30/50  train_mse=0.030230  val_mse=0.043091\n",
      "  epoch  40/50  train_mse=0.030310  val_mse=0.043526\n",
      "  epoch  50/50  train_mse=0.029957  val_mse=0.042950\n",
      "[G-7] thr=0.278431  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[P-7] train_windows=2202 val_windows=550 test_windows=7970 F_in=24\n",
      "  epoch   1/50  train_mse=0.115804  val_mse=0.062111\n",
      "  epoch  10/50  train_mse=0.057373  val_mse=0.064532\n",
      "  epoch  20/50  train_mse=0.057036  val_mse=0.064526\n",
      "  epoch  30/50  train_mse=0.057406  val_mse=0.063328\n",
      "  epoch  40/50  train_mse=0.056950  val_mse=0.065071\n",
      "  epoch  50/50  train_mse=0.056668  val_mse=0.064764\n",
      "[P-7] thr=0.078916  P=0.989 R=1.000 F1=0.995\n",
      "\n",
      "[R-1] train_windows=2219 val_windows=554 test_windows=7143 F_in=24\n",
      "  epoch   1/50  train_mse=0.710300  val_mse=0.050519\n",
      "  epoch  10/50  train_mse=0.000164  val_mse=0.000704\n",
      "  epoch  20/50  train_mse=0.000145  val_mse=0.000850\n",
      "  epoch  30/50  train_mse=0.000124  val_mse=0.000644\n",
      "  epoch  40/50  train_mse=0.000122  val_mse=0.000646\n",
      "  epoch  50/50  train_mse=0.000121  val_mse=0.000594\n",
      "[R-1] thr=0.002126  P=0.552 R=1.000 F1=0.711\n",
      "\n",
      "[A-5] train_windows=484 val_windows=120 test_windows=4592 F_in=24\n",
      "  epoch   1/50  train_mse=0.335448  val_mse=0.015394\n",
      "  epoch  10/50  train_mse=0.003858  val_mse=0.007835\n",
      "  epoch  20/50  train_mse=0.000564  val_mse=0.000068\n",
      "  epoch  30/50  train_mse=0.000209  val_mse=0.000547\n",
      "  epoch  40/50  train_mse=0.000131  val_mse=0.000447\n",
      "  epoch  50/50  train_mse=0.000121  val_mse=0.000334\n",
      "[A-5] thr=0.000136  P=0.021 R=1.000 F1=0.041\n",
      "\n",
      "[A-6] train_windows=465 val_windows=116 test_windows=4352 F_in=24\n",
      "  epoch   1/50  train_mse=0.078344  val_mse=0.531570\n",
      "  epoch  10/50  train_mse=0.003196  val_mse=0.256889\n",
      "  epoch  20/50  train_mse=0.001728  val_mse=0.281327\n",
      "  epoch  30/50  train_mse=0.001552  val_mse=0.276876\n",
      "  epoch  40/50  train_mse=0.001416  val_mse=0.279051\n",
      "  epoch  50/50  train_mse=0.001404  val_mse=0.279596\n",
      "[A-6] thr=0.237390  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[A-7] train_windows=2223 val_windows=555 test_windows=8530 F_in=24\n",
      "  epoch   1/50  train_mse=0.198090  val_mse=0.219734\n",
      "  epoch  10/50  train_mse=0.152508  val_mse=0.157393\n",
      "  epoch  20/50  train_mse=0.153319  val_mse=0.158392\n",
      "  epoch  30/50  train_mse=0.152720  val_mse=0.160966\n",
      "  epoch  40/50  train_mse=0.151020  val_mse=0.157338\n",
      "  epoch  50/50  train_mse=0.150547  val_mse=0.157498\n",
      "[A-7] thr=0.176458  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[D-13] train_windows=1112 val_windows=277 test_windows=7562 F_in=24\n",
      "  epoch   1/50  train_mse=0.536300  val_mse=0.209023\n",
      "  epoch  10/50  train_mse=0.000317  val_mse=0.001737\n",
      "  epoch  20/50  train_mse=0.000163  val_mse=0.000647\n",
      "  epoch  30/50  train_mse=0.000140  val_mse=0.000683\n",
      "  epoch  40/50  train_mse=0.000133  val_mse=0.000726\n",
      "  epoch  50/50  train_mse=0.000137  val_mse=0.000721\n",
      "[D-13] thr=0.001094  P=0.043 R=1.000 F1=0.083\n",
      "\n",
      "[P-2] train_windows=2176 val_windows=544 test_windows=8108 F_in=24\n",
      "  epoch   1/50  train_mse=0.106716  val_mse=0.012645\n",
      "  epoch  10/50  train_mse=0.001212  val_mse=0.000802\n",
      "  epoch  20/50  train_mse=0.001059  val_mse=0.000914\n",
      "  epoch  30/50  train_mse=0.000967  val_mse=0.001185\n",
      "  epoch  40/50  train_mse=0.000957  val_mse=0.001124\n",
      "  epoch  50/50  train_mse=0.000956  val_mse=0.001152\n",
      "[P-2] thr=0.009387  P=0.569 R=1.000 F1=0.725\n",
      "\n",
      "[A-8] train_windows=529 val_windows=132 test_windows=8274 F_in=24\n",
      "  epoch   1/50  train_mse=1.382748  val_mse=0.131566\n",
      "  epoch  10/50  train_mse=0.207781  val_mse=0.008308\n",
      "  epoch  20/50  train_mse=0.111625  val_mse=0.000538\n",
      "  epoch  30/50  train_mse=0.092289  val_mse=0.005955\n",
      "  epoch  40/50  train_mse=0.083010  val_mse=0.001909\n",
      "  epoch  50/50  train_mse=0.080710  val_mse=0.005168\n",
      "[A-8] thr=0.000933  P=0.460 R=1.000 F1=0.630\n",
      "\n",
      "[A-9] train_windows=529 val_windows=132 test_windows=8333 F_in=24\n",
      "  epoch   1/50  train_mse=1.128897  val_mse=0.058653\n",
      "  epoch  10/50  train_mse=0.439272  val_mse=0.178502\n",
      "  epoch  20/50  train_mse=0.118270  val_mse=0.016572\n",
      "  epoch  30/50  train_mse=0.092581  val_mse=0.007306\n",
      "  epoch  40/50  train_mse=0.082191  val_mse=0.004761\n",
      "  epoch  50/50  train_mse=0.081256  val_mse=0.006804\n",
      "[A-9] thr=0.000449  P=0.464 R=1.000 F1=0.634\n",
      "\n",
      "[F-3] train_windows=2224 val_windows=555 test_windows=8275 F_in=24\n",
      "  epoch   1/50  train_mse=0.236472  val_mse=0.784197\n",
      "  epoch  10/50  train_mse=0.199578  val_mse=1.127399\n",
      "  epoch  20/50  train_mse=0.167691  val_mse=0.986163\n",
      "  epoch  30/50  train_mse=0.158890  val_mse=1.057578\n",
      "  epoch  40/50  train_mse=0.153588  val_mse=1.002062\n",
      "  epoch  50/50  train_mse=0.152200  val_mse=1.028149\n",
      "[F-3] thr=0.158419  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[M-6] train_windows=1172 val_windows=292 test_windows=1948 F_in=54\n",
      "  epoch   1/50  train_mse=0.370329  val_mse=0.285083\n",
      "  epoch  10/50  train_mse=0.000696  val_mse=0.002425\n",
      "  epoch  20/50  train_mse=0.000195  val_mse=0.002244\n",
      "  epoch  30/50  train_mse=0.000177  val_mse=0.001679\n",
      "  epoch  40/50  train_mse=0.000164  val_mse=0.001445\n",
      "  epoch  50/50  train_mse=0.000169  val_mse=0.001412\n",
      "[M-6] thr=0.010688  P=0.173 R=1.000 F1=0.296\n",
      "\n",
      "[M-1] train_windows=1687 val_windows=421 test_windows=2176 F_in=54\n",
      "  epoch   1/50  train_mse=0.883468  val_mse=1.433589\n",
      "  epoch  10/50  train_mse=0.380098  val_mse=0.978276\n",
      "  epoch  20/50  train_mse=0.355953  val_mse=1.313365\n",
      "  epoch  30/50  train_mse=0.335020  val_mse=1.024371\n",
      "  epoch  40/50  train_mse=0.327649  val_mse=1.058048\n",
      "  epoch  50/50  train_mse=0.326695  val_mse=1.111759\n",
      "[M-1] thr=0.164552  P=0.684 R=1.000 F1=0.812\n",
      "\n",
      "[M-2] train_windows=1686 val_windows=421 test_windows=2176 F_in=54\n",
      "  epoch   1/50  train_mse=0.770845  val_mse=0.824929\n",
      "  epoch  10/50  train_mse=0.059413  val_mse=0.421516\n",
      "  epoch  20/50  train_mse=0.055407  val_mse=0.394769\n",
      "  epoch  30/50  train_mse=0.053275  val_mse=0.398971\n",
      "  epoch  40/50  train_mse=0.052572  val_mse=0.416391\n",
      "  epoch  50/50  train_mse=0.052274  val_mse=0.418810\n",
      "[M-2] thr=0.207320  P=0.985 R=1.000 F1=0.993\n",
      "\n",
      "[S-2] train_windows=660 val_windows=165 test_windows=1726 F_in=54\n",
      "  epoch   1/50  train_mse=0.878394  val_mse=0.031941\n",
      "  epoch  10/50  train_mse=0.002912  val_mse=0.009580\n",
      "  epoch  20/50  train_mse=0.000344  val_mse=0.002173\n",
      "  epoch  30/50  train_mse=0.000224  val_mse=0.000983\n",
      "  epoch  40/50  train_mse=0.000184  val_mse=0.000981\n",
      "  epoch  50/50  train_mse=0.000177  val_mse=0.001007\n",
      "[S-2] thr=0.004621  P=0.041 R=1.000 F1=0.078\n",
      "\n",
      "[P-10] train_windows=3366 val_windows=841 test_windows=5999 F_in=54\n",
      "  epoch   1/50  train_mse=1.138640  val_mse=0.003031\n",
      "  epoch  10/50  train_mse=0.000134  val_mse=0.000533\n",
      "  epoch  20/50  train_mse=0.000124  val_mse=0.000439\n",
      "  epoch  30/50  train_mse=0.000109  val_mse=0.000410\n",
      "  epoch  40/50  train_mse=0.000108  val_mse=0.000311\n",
      "  epoch  50/50  train_mse=0.000105  val_mse=0.000373\n",
      "[P-10] thr=0.002612  P=0.076 R=1.000 F1=0.142\n",
      "\n",
      "[T-4] train_windows=1737 val_windows=434 test_windows=2116 F_in=54\n",
      "  epoch   1/50  train_mse=0.775558  val_mse=0.439842\n",
      "  epoch  10/50  train_mse=0.246501  val_mse=0.243026\n",
      "  epoch  20/50  train_mse=0.228133  val_mse=0.213800\n",
      "  epoch  30/50  train_mse=0.221371  val_mse=0.209236\n",
      "  epoch  40/50  train_mse=0.218085  val_mse=0.206962\n",
      "  epoch  50/50  train_mse=0.216988  val_mse=0.205620\n",
      "[T-4] thr=0.109345  P=0.129 R=1.000 F1=0.228\n",
      "\n",
      "[T-5] train_windows=1737 val_windows=434 test_windows=2117 F_in=54\n",
      "  epoch   1/50  train_mse=0.130623  val_mse=0.011785\n",
      "  epoch  10/50  train_mse=0.000182  val_mse=0.000120\n",
      "  epoch  20/50  train_mse=0.000136  val_mse=0.000221\n",
      "  epoch  30/50  train_mse=0.000128  val_mse=0.000401\n",
      "  epoch  40/50  train_mse=0.000118  val_mse=0.000397\n",
      "  epoch  50/50  train_mse=0.000114  val_mse=0.000375\n",
      "[T-5] thr=0.002484  P=0.158 R=1.000 F1=0.273\n",
      "\n",
      "[F-7] train_windows=1928 val_windows=482 test_windows=4953 F_in=54\n",
      "  epoch   1/50  train_mse=0.734219  val_mse=0.394087\n",
      "  epoch  10/50  train_mse=0.357270  val_mse=0.394949\n",
      "  epoch  20/50  train_mse=0.352896  val_mse=0.385763\n",
      "  epoch  30/50  train_mse=0.337161  val_mse=0.369818\n",
      "  epoch  40/50  train_mse=0.328580  val_mse=0.374935\n",
      "  epoch  50/50  train_mse=0.328102  val_mse=0.368443\n",
      "[F-7] thr=0.258135  P=0.830 R=0.476 F1=0.605\n",
      "\n",
      "[M-3] train_windows=1549 val_windows=387 test_windows=2026 F_in=54\n",
      "  epoch   1/50  train_mse=0.746229  val_mse=0.547584\n",
      "  epoch  10/50  train_mse=0.518192  val_mse=0.306350\n",
      "  epoch  20/50  train_mse=0.519167  val_mse=0.286326\n",
      "  epoch  30/50  train_mse=0.442518  val_mse=0.493836\n",
      "  epoch  40/50  train_mse=0.400400  val_mse=0.374562\n",
      "  epoch  50/50  train_mse=0.393341  val_mse=0.358605\n",
      "[M-3] thr=0.280012  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[M-4] train_windows=1580 val_windows=395 test_windows=1937 F_in=54\n",
      "  epoch   1/50  train_mse=0.806579  val_mse=0.169944\n",
      "  epoch  10/50  train_mse=0.415527  val_mse=0.204516\n",
      "  epoch  20/50  train_mse=0.437077  val_mse=0.216010\n",
      "  epoch  30/50  train_mse=0.331465  val_mse=0.306882\n",
      "  epoch  40/50  train_mse=0.327837  val_mse=0.364299\n",
      "  epoch  50/50  train_mse=0.310726  val_mse=0.328714\n",
      "[M-4] thr=0.271551  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[M-5] train_windows=1545 val_windows=386 test_windows=2202 F_in=54\n",
      "  epoch   1/50  train_mse=0.589154  val_mse=0.739919\n",
      "  epoch  10/50  train_mse=0.399196  val_mse=0.806085\n",
      "  epoch  20/50  train_mse=0.386906  val_mse=0.660291\n",
      "  epoch  30/50  train_mse=0.378939  val_mse=0.690717\n",
      "  epoch  40/50  train_mse=0.376872  val_mse=0.704222\n",
      "  epoch  50/50  train_mse=0.376104  val_mse=0.699383\n",
      "[M-5] thr=0.179823  P=0.709 R=1.000 F1=0.830\n",
      "\n",
      "[P-15] train_windows=2865 val_windows=716 test_windows=2755 F_in=54\n",
      "  epoch   1/50  train_mse=0.122652  val_mse=0.012706\n",
      "  epoch  10/50  train_mse=0.000911  val_mse=0.000696\n",
      "  epoch  20/50  train_mse=0.000818  val_mse=0.000708\n",
      "  epoch  30/50  train_mse=0.000778  val_mse=0.001100\n",
      "  epoch  40/50  train_mse=0.000773  val_mse=0.000770\n",
      "  epoch  50/50  train_mse=0.000765  val_mse=0.000920\n",
      "[P-15] thr=0.008577  P=0.009 R=1.000 F1=0.017\n",
      "\n",
      "[C-1] train_windows=1646 val_windows=411 test_windows=2163 F_in=54\n",
      "  epoch   1/50  train_mse=0.210839  val_mse=0.134742\n",
      "  epoch  10/50  train_mse=0.140352  val_mse=0.114630\n",
      "  epoch  20/50  train_mse=0.119937  val_mse=0.083057\n",
      "  epoch  30/50  train_mse=0.114454  val_mse=0.077711\n",
      "  epoch  40/50  train_mse=0.111888  val_mse=0.078501\n",
      "  epoch  50/50  train_mse=0.111248  val_mse=0.079913\n",
      "[C-1] thr=0.083330  P=0.571 R=0.645 F1=0.606\n",
      "\n",
      "[C-2] train_windows=531 val_windows=132 test_windows=1950 F_in=54\n",
      "  epoch   1/50  train_mse=1.981811  val_mse=0.094669\n",
      "  epoch  10/50  train_mse=0.001173  val_mse=0.002808\n",
      "  epoch  20/50  train_mse=0.000185  val_mse=0.001589\n",
      "  epoch  30/50  train_mse=0.000157  val_mse=0.001596\n",
      "  epoch  40/50  train_mse=0.000131  val_mse=0.001697\n",
      "  epoch  50/50  train_mse=0.000150  val_mse=0.001735\n",
      "[C-2] thr=0.007782  P=0.077 R=1.000 F1=0.144\n",
      "\n",
      "[T-12] train_windows=836 val_windows=208 test_windows=2329 F_in=54\n",
      "  epoch   1/50  train_mse=0.363122  val_mse=0.258941\n",
      "  epoch  10/50  train_mse=0.238797  val_mse=0.143804\n",
      "  epoch  20/50  train_mse=0.236218  val_mse=0.233082\n",
      "  epoch  30/50  train_mse=0.231146  val_mse=0.254299\n",
      "  epoch  40/50  train_mse=0.225726  val_mse=0.264812\n",
      "  epoch  50/50  train_mse=0.224674  val_mse=0.266065\n",
      "[T-12] thr=0.126387  P=0.405 R=1.000 F1=0.577\n",
      "\n",
      "[T-13] train_windows=836 val_windows=208 test_windows=2329 F_in=54\n",
      "  epoch   1/50  train_mse=0.261651  val_mse=0.209804\n",
      "  epoch  10/50  train_mse=0.167293  val_mse=0.382895\n",
      "  epoch  20/50  train_mse=0.114311  val_mse=0.321520\n",
      "  epoch  30/50  train_mse=0.085406  val_mse=0.442433\n",
      "  epoch  40/50  train_mse=0.051867  val_mse=0.758868\n",
      "  epoch  50/50  train_mse=0.046870  val_mse=0.777510\n",
      "[T-13] thr=0.113436  P=0.000 R=0.000 F1=0.000\n",
      "\n",
      "[F-4] train_windows=1715 val_windows=428 test_windows=3321 F_in=54\n",
      "  epoch   1/50  train_mse=0.953923  val_mse=0.232641\n",
      "  epoch  10/50  train_mse=0.131279  val_mse=0.037142\n",
      "  epoch  20/50  train_mse=0.106139  val_mse=0.037981\n",
      "  epoch  30/50  train_mse=0.100793  val_mse=0.044743\n",
      "  epoch  40/50  train_mse=0.099610  val_mse=0.049669\n",
      "  epoch  50/50  train_mse=0.097984  val_mse=0.053520\n",
      "[F-4] thr=0.079213  P=0.076 R=1.000 F1=0.142\n",
      "\n",
      "[F-5] train_windows=1998 val_windows=499 test_windows=3821 F_in=54\n",
      "  epoch   1/50  train_mse=0.559632  val_mse=0.066785\n",
      "  epoch  10/50  train_mse=0.492238  val_mse=0.051675\n",
      "  epoch  20/50  train_mse=0.488168  val_mse=0.220055\n",
      "  epoch  30/50  train_mse=0.448269  val_mse=0.121473\n",
      "  epoch  40/50  train_mse=0.441398  val_mse=0.150939\n",
      "  epoch  50/50  train_mse=0.439096  val_mse=0.147629\n",
      "[F-5] thr=0.075358  P=0.134 R=1.000 F1=0.236\n",
      "\n",
      "[D-14] train_windows=2860 val_windows=714 test_windows=2524 F_in=54\n",
      "  epoch   1/50  train_mse=0.039500  val_mse=0.004647\n",
      "  epoch  10/50  train_mse=0.000206  val_mse=0.000887\n",
      "  epoch  20/50  train_mse=0.000119  val_mse=0.000469\n",
      "  epoch  30/50  train_mse=0.000117  val_mse=0.000424\n",
      "  epoch  40/50  train_mse=0.000107  val_mse=0.000314\n",
      "  epoch  50/50  train_mse=0.000104  val_mse=0.000391\n",
      "[D-14] thr=0.002480  P=0.206 R=1.000 F1=0.342\n",
      "\n",
      "[T-9] train_windows=271 val_windows=67 test_windows=995 F_in=54\n",
      "  epoch   1/50  train_mse=0.035330  val_mse=0.075890\n",
      "  epoch  10/50  train_mse=0.003876  val_mse=0.013729\n",
      "  epoch  20/50  train_mse=0.003774  val_mse=0.006767\n",
      "  epoch  30/50  train_mse=0.003484  val_mse=0.007711\n",
      "  epoch  40/50  train_mse=0.003532  val_mse=0.007500\n",
      "  epoch  50/50  train_mse=0.003609  val_mse=0.007127\n",
      "[T-9] thr=0.063554  P=0.346 R=1.000 F1=0.514\n",
      "\n",
      "[P-14] train_windows=2224 val_windows=555 test_windows=5999 F_in=54\n",
      "  epoch   1/50  train_mse=0.016693  val_mse=0.003589\n",
      "  epoch  10/50  train_mse=0.000192  val_mse=0.000215\n",
      "  epoch  20/50  train_mse=0.000178  val_mse=0.000441\n",
      "  epoch  30/50  train_mse=0.000126  val_mse=0.000482\n",
      "  epoch  40/50  train_mse=0.000126  val_mse=0.000290\n",
      "  epoch  50/50  train_mse=0.000123  val_mse=0.000312\n",
      "[P-14] thr=0.001408  P=0.033 R=1.000 F1=0.064\n",
      "\n",
      "[T-8] train_windows=518 val_windows=129 test_windows=1418 F_in=54\n",
      "  epoch   1/50  train_mse=1.006252  val_mse=0.032709\n",
      "  epoch  10/50  train_mse=0.036138  val_mse=0.030918\n",
      "  epoch  20/50  train_mse=0.036270  val_mse=0.030924\n",
      "  epoch  30/50  train_mse=0.035415  val_mse=0.032019\n",
      "  epoch  40/50  train_mse=0.035193  val_mse=0.032797\n",
      "  epoch  50/50  train_mse=0.035409  val_mse=0.031532\n",
      "[T-8] thr=0.102323  P=0.855 R=1.000 F1=0.922\n",
      "\n",
      "[P-11] train_windows=3095 val_windows=773 test_windows=3434 F_in=54\n",
      "  epoch   1/50  train_mse=0.028326  val_mse=0.013881\n",
      "  epoch  10/50  train_mse=0.015617  val_mse=0.013086\n",
      "  epoch  20/50  train_mse=0.013138  val_mse=0.008310\n",
      "  epoch  30/50  train_mse=0.012679  val_mse=0.009555\n",
      "  epoch  40/50  train_mse=0.012580  val_mse=0.008061\n",
      "  epoch  50/50  train_mse=0.012430  val_mse=0.008748\n",
      "[P-11] thr=0.037836  P=0.592 R=1.000 F1=0.743\n",
      "\n",
      "[D-15] train_windows=1579 val_windows=394 test_windows=2057 F_in=54\n",
      "  epoch   1/50  train_mse=0.555177  val_mse=0.430400\n",
      "  epoch  10/50  train_mse=0.433339  val_mse=0.381697\n",
      "  epoch  20/50  train_mse=0.441118  val_mse=0.387683\n",
      "  epoch  30/50  train_mse=0.414455  val_mse=0.369818\n",
      "  epoch  40/50  train_mse=0.411905  val_mse=0.371211\n",
      "  epoch  50/50  train_mse=0.408444  val_mse=0.369564\n",
      "[D-15] thr=0.271314  P=0.965 R=1.000 F1=0.982\n",
      "\n",
      "[D-16] train_windows=1080 val_windows=270 test_windows=2090 F_in=54\n",
      "  epoch   1/50  train_mse=0.763648  val_mse=0.513762\n",
      "  epoch  10/50  train_mse=0.363011  val_mse=0.513845\n",
      "  epoch  20/50  train_mse=0.364268  val_mse=0.762823\n",
      "  epoch  30/50  train_mse=0.345109  val_mse=0.885283\n",
      "  epoch  40/50  train_mse=0.343663  val_mse=0.879020\n",
      "  epoch  50/50  train_mse=0.342775  val_mse=0.880953\n",
      "[D-16] thr=0.101132  P=0.982 R=1.000 F1=0.991\n",
      "\n",
      "[M-7] train_windows=1189 val_windows=297 test_windows=2055 F_in=54\n",
      "  epoch   1/50  train_mse=0.474324  val_mse=0.077820\n",
      "  epoch  10/50  train_mse=0.018578  val_mse=0.000530\n",
      "  epoch  20/50  train_mse=0.017906  val_mse=0.000493\n",
      "  epoch  30/50  train_mse=0.017750  val_mse=0.000451\n",
      "  epoch  40/50  train_mse=0.017913  val_mse=0.000457\n",
      "  epoch  50/50  train_mse=0.017777  val_mse=0.000526\n",
      "[M-7] thr=0.005876  P=0.730 R=1.000 F1=0.844\n",
      "\n",
      "[F-8] train_windows=2593 val_windows=648 test_windows=2386 F_in=54\n",
      "  epoch   1/50  train_mse=0.677171  val_mse=0.318232\n",
      "  epoch  10/50  train_mse=0.232003  val_mse=0.307743\n",
      "  epoch  20/50  train_mse=0.218313  val_mse=0.303610\n",
      "  epoch  30/50  train_mse=0.211658  val_mse=0.299258\n",
      "  epoch  40/50  train_mse=0.209926  val_mse=0.300842\n",
      "  epoch  50/50  train_mse=0.208650  val_mse=0.300984\n",
      "[F-8] thr=0.244379  P=0.994 R=1.000 F1=0.997\n",
      "\n",
      "Saved metrics: results/anomaly_transformer/per_channel_metrics.csv\n",
      "  chan_id  precision    recall        f1  threshold\n",
      "0     P-1   0.000000  0.000000  0.000000   0.183677\n",
      "1     S-1   0.768041  1.000000  0.868805   0.163716\n",
      "2     E-1   0.903226  0.940711  0.921588   0.274454\n",
      "3     E-2   0.928856  1.000000  0.963116   0.193617\n",
      "4     E-3   0.880965  1.000000  0.936716   0.140888\n",
      "5     E-4   0.984244  1.000000  0.992059   0.161625\n",
      "6     E-5   1.000000  1.000000  1.000000   0.276373\n",
      "7     E-6   0.109983  1.000000  0.198171   0.003270\n",
      "8     E-7   0.793201  1.000000  0.884676   0.013690\n",
      "9     E-8   0.938160  1.000000  0.968093   0.158087\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Mean Precision: 0.4501\n",
      "Mean Recall:    0.8083\n",
      "Mean F1:        0.5026\n",
      "Channels with F1 > 0.5: 45 / 82\n"
     ]
    }
   ],
   "source": [
    "# --- Per-channel AnomalyTransformer forecasting anomaly detection (unsupervised) ---\n",
    "# Goal: train ONE model per chan_id on train/ .npy (normal-only),\n",
    "#       predict future column 0 using history of columns 1..F-1,\n",
    "#       then detect anomalies in test via high prediction error + association discrepancy.\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# -----------------------------\n",
    "# Config (mirrors your notebook exactly)\n",
    "# -----------------------------\n",
    "INPUT_DIR = Path(\"DataSet\")\n",
    "LABEL_FILE = INPUT_DIR / \"labeled_anomalies.csv\"\n",
    "TRAIN_DIR = INPUT_DIR / \"data/data/train\"\n",
    "TEST_DIR = INPUT_DIR / \"data/data/test\"\n",
    "\n",
    "OUT_MODELS_DIR = Path(\"models\") / \"anomaly_transformer\"\n",
    "OUT_RESULTS_DIR = Path(\"results\") / \"anomaly_transformer\"\n",
    "OUT_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Forecasting window params (Telemanom-style)\n",
    "L_S = 100               # history length\n",
    "N_PRED = 1              # forecast horizon (start with 1)\n",
    "STRIDE = 1              # step size in window generation\n",
    "\n",
    "# Training params (per channel)\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50             # Transformers converge faster than CNNs\n",
    "LR = 1e-4\n",
    "DROPOUT = 0.2\n",
    "VAL_FRAC = 0.2\n",
    "\n",
    "# Thresholding (from validation error distribution)\n",
    "THRESH_Q = 0.995        # 99.5th percentile\n",
    "\n",
    "# Scaling mode: \"none\" (Telemanom data already scaled) or \"standard\"\n",
    "SCALE_MODE = \"none\"\n",
    "\n",
    "# For quick testing: set to int (e.g., 5). Use None for all channels.\n",
    "MAX_CHANNELS = None\n",
    "\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"Window params: {{'L_S': {L_S}, 'N_PRED': {N_PRED}, 'STRIDE': {STRIDE}}}\")\n",
    "print(f\"Train params: {{'BATCH_SIZE': {BATCH_SIZE}, 'EPOCHS': {EPOCHS}, 'LR': {LR}, 'VAL_FRAC': {VAL_FRAC}}}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Data utilities (identical to your notebook)\n",
    "# -----------------------------\n",
    "def load_chan_train_test(chan_id: str):\n",
    "    \"\"\"Load (train, test) arrays for a single channel.\"\"\"\n",
    "    train_path = TRAIN_DIR / f\"{chan_id}.npy\"\n",
    "    test_path = TEST_DIR / f\"{chan_id}.npy\"\n",
    "\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        return None, None, None\n",
    "\n",
    "    x_train = np.load(train_path).astype(np.float32)\n",
    "    x_test = np.load(test_path).astype(np.float32)\n",
    "\n",
    "    if x_train.ndim != 2 or x_test.ndim != 2:\n",
    "        return None, None, None\n",
    "    if x_train.shape[1] != x_test.shape[1]:\n",
    "        return None, None, None\n",
    "\n",
    "    if SCALE_MODE == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train).astype(np.float32)\n",
    "        x_test = scaler.transform(x_test).astype(np.float32)\n",
    "        return x_train, x_test, scaler\n",
    "\n",
    "    return x_train, x_test, None\n",
    "\n",
    "\n",
    "def build_forecast_windows(x: np.ndarray, l_s: int, n_pred: int = 1, stride: int = 1, use_other_features_only: bool = True):\n",
    "    \"\"\"Telemanom-style forecasting windows.\"\"\"\n",
    "    assert x.ndim == 2\n",
    "    T, F = x.shape\n",
    "    if use_other_features_only:\n",
    "        if F < 2:\n",
    "            return None, None, None\n",
    "        x_in = x[:, 1:]\n",
    "    else:\n",
    "        x_in = x\n",
    "\n",
    "    max_i = T - l_s - n_pred\n",
    "    if max_i <= 0:\n",
    "        return None, None, None\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in range(0, max_i, stride):\n",
    "        X_list.append(x_in[i : i + l_s])\n",
    "        y_list.append(x[i + l_s : i + l_s + n_pred, 0])\n",
    "\n",
    "    X = np.stack(X_list).astype(np.float32)\n",
    "    y = np.stack(y_list).astype(np.float32)\n",
    "    t0 = l_s\n",
    "    return X, y, t0\n",
    "\n",
    "\n",
    "def anomaly_vector_from_sequences(T: int, anomaly_sequences) -> np.ndarray:\n",
    "    \"\"\"Build point-wise 0/1 anomaly vector from CSV sequences.\"\"\"\n",
    "    y = np.zeros(T, dtype=np.int64)\n",
    "    for start, end in anomaly_sequences:\n",
    "        start = max(0, int(start))\n",
    "        end = min(T, int(end))\n",
    "        if start < end:\n",
    "            y[start:end] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def contiguous_sequences_from_flags(flags: np.ndarray, offset: int = 0):\n",
    "    \"\"\"Convert boolean flags into [start,end) sequences.\"\"\"\n",
    "    flags = np.asarray(flags).astype(bool)\n",
    "    seqs = []\n",
    "    in_run = False\n",
    "    run_start = 0\n",
    "    for i, f in enumerate(flags):\n",
    "        if f and not in_run:\n",
    "            in_run = True\n",
    "            run_start = i\n",
    "        elif (not f) and in_run:\n",
    "            in_run = False\n",
    "            seqs.append([run_start + offset, i + offset])\n",
    "    if in_run:\n",
    "        seqs.append([run_start + offset, len(flags) + offset])\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def precision_recall_f1(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    y_pred = y_pred.astype(np.int64)\n",
    "    tp = int(np.sum((y_true == 1) & (y_pred == 1)))\n",
    "    fp = int(np.sum((y_true == 0) & (y_pred == 1)))\n",
    "    fn = int(np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "    return dict(tp=tp, fp=fp, fn=fn, precision=prec, recall=rec, f1=f1)\n",
    "\n",
    "\n",
    "def point_adjust_predictions(y_true_full: np.ndarray, y_pred_full: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Telemanom/NAB-style point adjustment.\"\"\"\n",
    "    y_true_full = y_true_full.astype(np.int64)\n",
    "    y_pred_full = y_pred_full.astype(np.int64)\n",
    "    y_adj = y_pred_full.copy()\n",
    "\n",
    "    in_seg = False\n",
    "    seg_start = 0\n",
    "    for i in range(len(y_true_full) + 1):\n",
    "        cur = y_true_full[i] if i < len(y_true_full) else 0\n",
    "        if cur == 1 and not in_seg:\n",
    "            in_seg = True\n",
    "            seg_start = i\n",
    "        elif cur == 0 and in_seg:\n",
    "            in_seg = False\n",
    "            seg_end = i\n",
    "            if np.any(y_pred_full[seg_start:seg_end] == 1):\n",
    "                y_adj[seg_start:seg_end] = 1\n",
    "\n",
    "    return y_adj\n",
    "\n",
    "\n",
    "def precision_recall_f1_point_adjusted(y_true_full: np.ndarray, y_pred_full: np.ndarray):\n",
    "    y_adj = point_adjust_predictions(y_true_full, y_pred_full)\n",
    "    return precision_recall_f1(y_true_full, y_adj)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# AnomalyTransformer Core (ICLR 2022) - FIXED DIMENSION HANDLING\n",
    "# -----------------------------\n",
    "class AnomalyAttention(nn.Module):\n",
    "    \"\"\"Key innovation: learns series-wise and prior association to compute discrepancy\"\"\"\n",
    "    def __init__(self, d_model: int, n_heads: int = 8):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Learnable prior for association discrepancy\n",
    "        self.u = nn.Parameter(torch.randn(n_heads, 1, 1) * 0.1)  # Small init for stability\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        B, L, D = x.shape\n",
    "        \n",
    "        # Project queries, keys, values\n",
    "        Q = self.q_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_proj(x).view(B, L, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Series-wise association (normalized attention)\n",
    "        attn_series = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
    "        attn_series = F.softmax(attn_series, dim=-1)\n",
    "        \n",
    "        # Prior association (learnable Gaussian prior)\n",
    "        positions = torch.arange(L, device=x.device).float()\n",
    "        prior = torch.abs(positions.unsqueeze(0) - positions.unsqueeze(1))\n",
    "        prior = prior.unsqueeze(0).unsqueeze(0).expand(B, self.n_heads, L, L)\n",
    "        attn_prior = torch.exp(-prior ** 2 / (2 * (self.u ** 2 + 1e-6)))\n",
    "        attn_prior = attn_prior / (attn_prior.sum(dim=-1, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Association discrepancy (key innovation)\n",
    "        discrepancy = torch.abs(attn_series - attn_prior).mean(dim=(1, 2))\n",
    "        \n",
    "        # Weighted value aggregation\n",
    "        out = torch.matmul(attn_series, V).transpose(1, 2).contiguous().view(B, L, D)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        return out, discrepancy\n",
    "\n",
    "\n",
    "class AnomalyTransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention = AnomalyAttention(d_model, n_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        attn_out, discrepancy = self.attention(x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        return x, discrepancy\n",
    "\n",
    "\n",
    "class AnomalyTransformerForecaster(nn.Module):\n",
    "    \"\"\"\n",
    "    Forecasting variant: predicts next value of channel 0 using history of other channels\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,      # Features from OTHER channels (columns 1..F-1)\n",
    "        d_model: int = 128,\n",
    "        n_layers: int = 3,\n",
    "        n_heads: int = 8,\n",
    "        window_size: int = 100,\n",
    "        n_pred: int = 1,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.n_pred = n_pred\n",
    "        \n",
    "        # Input projection (handles variable input dimensions)\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Transformer encoder stack\n",
    "        self.layers = nn.ModuleList([\n",
    "            AnomalyTransformerBlock(d_model, n_heads, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Forecasting head (predicts next n_pred values of target channel)\n",
    "        self.forecast_head = nn.Linear(d_model, n_pred)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, window_size, input_dim] - history of OTHER channels\n",
    "        Returns:\n",
    "            forecast: [batch, n_pred] - predicted values for target channel\n",
    "            discrepancy: [batch, window_size] - anomaly scores per timestep\n",
    "        \"\"\"\n",
    "        # Project to model dimension\n",
    "        x_proj = self.input_proj(x)\n",
    "        \n",
    "        # Pass through transformer layers (accumulate discrepancies)\n",
    "        total_discrepancy = 0\n",
    "        for layer in self.layers:\n",
    "            x_proj, disc = layer(x_proj)\n",
    "            total_discrepancy += disc\n",
    "        \n",
    "        # Average discrepancies across layers\n",
    "        avg_discrepancy = total_discrepancy / len(self.layers)\n",
    "        \n",
    "        # Forecast from last timestep representation\n",
    "        context = x_proj.mean(dim=1)  # [B, D]\n",
    "        forecast = self.forecast_head(context)  # [B, n_pred]\n",
    "        \n",
    "        return forecast, avg_discrepancy\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset & Training Utilities (IDENTICAL structure to your CNN)\n",
    "# -----------------------------\n",
    "class ForecastWindowDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "def split_train_val_sequential(X: np.ndarray, y: np.ndarray, val_frac: float = 0.2):\n",
    "    n = len(X)\n",
    "    n_val = max(int(n * val_frac), 1)\n",
    "    n_train = n - n_val\n",
    "    if n_train <= 0:\n",
    "        return None\n",
    "    X_tr, y_tr = X[:n_train], y[:n_train]\n",
    "    X_va, y_va = X[n_train:], y[n_train:]\n",
    "    return X_tr, y_tr, X_va, y_va\n",
    "\n",
    "\n",
    "def train_transformer(model, train_loader, val_loader, epochs: int, lr: float, device: str, chan_id: str):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred, _ = model(xb)\n",
    "            loss = criterion(pred, yb)  # Shape-safe: [B, n_pred] vs [B, n_pred]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            tr_loss += loss.item() * xb.size(0)\n",
    "        tr_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                pred, _ = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                va_loss += loss.item() * xb.size(0)\n",
    "        va_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if va_loss < best_val_loss:\n",
    "            best_val_loss = va_loss\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "        if epoch == 1 or epoch % max(1, epochs // 5) == 0 or epoch == epochs:\n",
    "            print(f\"  epoch {epoch: >3}/{epochs}  train_mse={tr_loss:.6f}  val_mse={va_loss:.6f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_anomaly_scores(model, loader, device: str, n_pred: int = 1):\n",
    "    \"\"\"FIXED: Handles n_pred=1 correctly without dimension errors\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    discrepancies = []\n",
    "    \n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred, disc = model(xb)\n",
    "        \n",
    "        # FIXED: Compute per-sample MSE correctly for any n_pred\n",
    "        # pred: [B, n_pred], yb: [B, n_pred]  error: [B]\n",
    "        error = ((pred - yb) ** 2).mean(dim=1).cpu().numpy()  # Mean over prediction horizon\n",
    "        \n",
    "        errors.append(error)\n",
    "        discrepancies.append(disc.mean(dim=1).cpu().numpy())  # Mean over time window\n",
    "    \n",
    "    errors = np.concatenate(errors)\n",
    "    discrepancies = np.concatenate(discrepancies)\n",
    "    \n",
    "    # Combined anomaly score (geometric mean for balance)\n",
    "    combined = np.sqrt(errors * discrepancies + 1e-8)\n",
    "    return combined\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Per-Channel Training Pipeline (IDENTICAL to your CNN structure)\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "def save_channel_model(chan_id: str, model, threshold: float, config: dict, out_dir: Path = Path(\"streaming_models\")):\n",
    "    \"\"\"Save model + metadata for streaming consumption\"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save PyTorch model\n",
    "    model_path = out_dir / f\"{chan_id}.pt\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_type': model.__class__.__name__,\n",
    "        'input_dim': getattr(model, 'input_dim', getattr(model, 'features_in', None)),\n",
    "        'window_size': getattr(model, 'window_size', config['L_S']),\n",
    "        'n_pred': getattr(model, 'n_pred', config['N_PRED']),\n",
    "    }, model_path)\n",
    "    \n",
    "    # Save metadata (threshold + config)\n",
    "    meta_path = out_dir / f\"{chan_id}_metadata.json\"\n",
    "    metadata = {\n",
    "        'chan_id': chan_id,\n",
    "        'threshold': float(threshold),\n",
    "        'window_size': config['L_S'],\n",
    "        'n_pred': config['N_PRED'],\n",
    "        'stride': config['STRIDE'],\n",
    "        'model_type': model.__class__.__name__,\n",
    "        'input_features': getattr(model, 'input_dim', getattr(model, 'features_in', None)),\n",
    "        'training_config': config\n",
    "    }\n",
    "    with open(meta_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\" Saved {chan_id} model to {model_path} + metadata\")\n",
    "    return model_path, meta_path\n",
    "\n",
    "def get_anomaly_sequences_for_chan(df: pd.DataFrame, chan_id: str):\n",
    "    row = df[df[\"chan_id\"] == chan_id]\n",
    "    if len(row) == 0:\n",
    "        return []\n",
    "    s = row.iloc[0][\"anomaly_sequences\"]\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def run_one_channel(chan_id: str, verbose: bool = True):\n",
    "    x_train, x_test, scaler = load_chan_train_test(chan_id)\n",
    "    if x_train is None:\n",
    "        if verbose:\n",
    "            print(f\"[{chan_id}] missing or invalid train/test\")\n",
    "        return None\n",
    "\n",
    "    # Build windows (forecasting setup: predict col 0 from cols 1..F-1)\n",
    "    X_tr_all, y_tr_all, t0_tr = build_forecast_windows(\n",
    "        x_train, l_s=L_S, n_pred=N_PRED, stride=STRIDE, use_other_features_only=True\n",
    "    )\n",
    "    X_te, y_te, t0_te = build_forecast_windows(\n",
    "        x_test, l_s=L_S, n_pred=N_PRED, stride=STRIDE, use_other_features_only=True\n",
    "    )\n",
    "    if X_tr_all is None or X_te is None:\n",
    "        if verbose:\n",
    "            print(f\"[{chan_id}] not enough length for windows\")\n",
    "        return None\n",
    "\n",
    "    split = split_train_val_sequential(X_tr_all, y_tr_all, val_frac=VAL_FRAC)\n",
    "    if split is None:\n",
    "        if verbose:\n",
    "            print(f\"[{chan_id}] not enough train windows to split\")\n",
    "        return None\n",
    "\n",
    "    X_tr, y_tr, X_va, y_va = split\n",
    "\n",
    "    train_ds = ForecastWindowDataset(X_tr, y_tr)\n",
    "    val_ds = ForecastWindowDataset(X_va, y_va)\n",
    "    test_ds = ForecastWindowDataset(X_te, y_te)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize AnomalyTransformer (input_dim = F-1 other channels)\n",
    "    model = AnomalyTransformerForecaster(\n",
    "        input_dim=X_tr.shape[2],\n",
    "        d_model=128,\n",
    "        n_layers=3,\n",
    "        n_heads=8,\n",
    "        window_size=L_S,\n",
    "        n_pred=N_PRED,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n[{chan_id}] train_windows={len(train_ds)} val_windows={len(val_ds)} \"\n",
    "              f\"test_windows={len(test_ds)} F_in={X_tr.shape[2]}\")\n",
    "\n",
    "    # Train model\n",
    "    model = train_transformer(\n",
    "        model, train_loader, val_loader,\n",
    "        epochs=EPOCHS, lr=LR, device=DEVICE, chan_id=chan_id\n",
    "    )\n",
    "\n",
    "    # Compute anomaly scores on validation set for thresholding (FIXED call)\n",
    "    val_scores = predict_anomaly_scores(model, val_loader, device=DEVICE, n_pred=N_PRED)\n",
    "    thr = float(np.quantile(val_scores, THRESH_Q))\n",
    "    \n",
    "    # Compute scores on test set\n",
    "    test_scores = predict_anomaly_scores(model, test_loader, device=DEVICE, n_pred=N_PRED)\n",
    "    pred_flags = (test_scores > thr).astype(np.int64)\n",
    "\n",
    "    # Align with ground truth\n",
    "    anomaly_seqs = get_anomaly_sequences_for_chan(df_labels, chan_id)\n",
    "    gt_full = anomaly_vector_from_sequences(T=x_test.shape[0], anomaly_sequences=anomaly_seqs)\n",
    "\n",
    "    # Map window predictions to original time indices\n",
    "    pred_indices = t0_te + np.arange(len(pred_flags)) * STRIDE\n",
    "    pred_indices = pred_indices.astype(np.int64)\n",
    "    valid = pred_indices < len(gt_full)\n",
    "    pred_indices = pred_indices[valid]\n",
    "    y_pred_pts = pred_flags[valid]\n",
    "    y_true_pts = gt_full[pred_indices]\n",
    "\n",
    "    # Point-adjusted metrics (standard in NASA anomaly detection papers)\n",
    "    metrics = precision_recall_f1_point_adjusted(y_true_pts, y_pred_pts)\n",
    "\n",
    "    # Save model\n",
    "    save_path = OUT_MODELS_DIR / f\"{chan_id}.pt\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"chan_id\": chan_id,\n",
    "            \"state_dict\": {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "            \"input_dim\": int(X_tr.shape[2]),\n",
    "            \"l_s\": int(L_S),\n",
    "            \"n_pred\": int(N_PRED),\n",
    "            \"stride\": int(STRIDE),\n",
    "            \"thr_q\": float(THRESH_Q),\n",
    "            \"threshold\": float(thr),\n",
    "            \"scaler_mean\": None if scaler is None else scaler.mean_.astype(np.float32),\n",
    "            \"scaler_scale\": None if scaler is None else scaler.scale_.astype(np.float32),\n",
    "        },\n",
    "        save_path,\n",
    "    )\n",
    "\n",
    "    out = {\n",
    "        \"chan_id\": chan_id,\n",
    "        \"T_train\": int(x_train.shape[0]),\n",
    "        \"T_test\": int(x_test.shape[0]),\n",
    "        \"F\": int(x_train.shape[1]),\n",
    "        \"F_in\": int(X_tr.shape[2]),\n",
    "        \"n_train_windows\": int(len(train_ds)),\n",
    "        \"n_val_windows\": int(len(val_ds)),\n",
    "        \"n_test_windows\": int(len(test_ds)),\n",
    "        \"threshold\": float(thr),\n",
    "        \"tp\": metrics[\"tp\"],\n",
    "        \"fp\": metrics[\"fp\"],\n",
    "        \"fn\": metrics[\"fn\"],\n",
    "        \"precision\": metrics[\"precision\"],\n",
    "        \"recall\": metrics[\"recall\"],\n",
    "        \"f1\": metrics[\"f1\"],\n",
    "        \"pred_sequences\": contiguous_sequences_from_flags(y_pred_pts.astype(bool), offset=int(pred_indices[0]) if len(pred_indices) else t0_te),\n",
    "        \"true_sequences\": anomaly_seqs,\n",
    "        \"model_path\": str(save_path),\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[{chan_id}] thr={thr:.6f}  P={metrics['precision']:.3f} R={metrics['recall']:.3f} F1={metrics['f1']:.3f}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df_labels = pd.read_csv(LABEL_FILE)\n",
    "    print(f\"Loaded labels: {df_labels.shape}\")\n",
    "    print(df_labels.head(3))\n",
    "\n",
    "    results = []\n",
    "    chan_ids = df_labels[\"chan_id\"].tolist()\n",
    "\n",
    "    if MAX_CHANNELS is not None:\n",
    "        chan_ids = chan_ids[:int(MAX_CHANNELS)]\n",
    "\n",
    "    print(f\"\\nTotal channels to run: {len(chan_ids)}\\n\")\n",
    "\n",
    "    for cid in chan_ids:\n",
    "        r = run_one_channel(cid, verbose=True)\n",
    "        if r is not None:\n",
    "            results.append(r)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_path = OUT_RESULTS_DIR / \"per_channel_metrics.csv\"\n",
    "    res_df.to_csv(res_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved metrics: {res_path}\")\n",
    "    print(res_df[[\"chan_id\", \"precision\", \"recall\", \"f1\", \"threshold\"]].head(10))\n",
    "    \n",
    "    # Summary statistics\n",
    "    if len(results) > 0:\n",
    "        print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "        print(f\"Mean Precision: {res_df['precision'].mean():.4f}\")\n",
    "        print(f\"Mean Recall:    {res_df['recall'].mean():.4f}\")\n",
    "        print(f\"Mean F1:        {res_df['f1'].mean():.4f}\")\n",
    "        print(f\"Channels with F1 > 0.5: {(res_df['f1'] > 0.5).sum()} / {len(res_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
